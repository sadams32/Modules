---
title: "Module8"
format: html
editor: visual
---

```{r}
install.packages("manipulate")
```

# Notes

Population

:   includes all of the elements from a set of data = N

Sample

:   one or more observations from a population = n

Parameter

:   a measurable characteristic of a population

Statistic

:   a measurable characteristic about a sample

When we do **statistical inference** we are basically trying to draw conclusions about a population based on measurements from a noisy sample or trying to evaluate whether it is reasonable to assume that our sample is drawn from a particular population.

# Probability

### Example: Rolling a Die

We will use the {manipulate} package and the sample() function to explore the effects of sample size on estimates of the probability of different outcomes. The probability of each outcome (rolling a ‚Äú1‚Äù, ‚Äú2‚Äù,‚Ä¶, ‚Äú6‚Äù) is 1 in 6, but our estimate of the probability of each possible outcome will change with sample size.

NOTE: To run {manipulate} effectively, you must run the code directly in the console (i.e., copy and paste the code into the console; using the ‚Äògreen arrow‚Äô or ‚ÄòRun‚Äô buttons on a {manipulate} chunk won‚Äôt have the desired effect). When you run the code as pasted into the console, the graph will appear in the Plots tab of your lower right RStudio pane. Once there, look to the upper left corner of the graph and you should see a small image of a gear. Click on the gear image and a slider will appear, allowing you to manipulate/toggle the sample size (n) of die rolls used to generate the graph.

In this particular graph, you should be able to see the difference in random sampling distribution of die roll outcomes for a given sample size, and how they change as sample size changes.

```{r}
library(manipulate)
outcomes <- c(1, 2, 3, 4, 5, 6)
manipulate(hist(sample(outcomes, n, replace = TRUE), breaks = c(0.5, 1.5, 2.5,
    3.5, 4.5, 5.5, 6.5), probability = TRUE, main = paste("Histogram of Outcomes of ",
    n, " Die Rolls", sep = ""), xlab = "roll", ylab = "probability"), n = slider(0,
    10000, initial = 10, step = 10))
```

## Challenge 1

Write a function to simulate rolling a die where you pass the number of rolls as an argument. Then, use your function to simulate rolling two dice 1000 times and take the sum of the rolls. Plot a histogram of those results.

```{r}
nrolls <- 1000
roll <- function(x) {
    sample(1:6, x, replace = TRUE) # size = x = the number of elements you want to randomly sample from 1:6.
}
two_dice <- roll(nrolls) + roll(nrolls)
hist(two_dice, breaks = c(1.5:12.5), probability = TRUE, main = "Rolling Two Dice",
    xlab = "sum of rolls", ylab = "probability")
```

## Challenge 2

You have a deck of 52 cards, Ace to 10 + 3 face cards in each suit. You draw a card at random.

```{r}
ndraw <- 10000
draw <- function(x) {
  sample(deck, x, replace = TRUE)
}
```

What is the probability that you draw a face card?

```{r}
deck <- c(rep("Face Card", 12), rep("Other", 40))
draws1 <- draw(ndraw)
prob1 = mean(draws1 == "Face Card")
prob1
```

What is the probability that you draw a King?

```{r}
deck <- c(rep("King", 4), rep("Other", 48))
draws2 <- draw(ndraw)
prob2 = mean(draws2 == "King")
prob2
```

What is the probability that you draw a spade?

```{r}
deck <- c(rep("Spade", 13), rep("Other",39))
draws3 <- draw(ndraw)
prob3 = mean(draws3 == "Spade")
prob3
```

What is the probability that you draw a spade given that you draw a face card?

What is the probability that you draw a King given that you draw a face card?

What is the probability that you draw a card that is both from a red suit (hearts or diamonds) and a face card?

# Random Variables

A random variable is a variable whose outcomes are assumed to arise by chance or according to some random or stochastic mechanism. The chances of observing a specific outcome or an outcome value within a specific interval has associated with it a probability.

A probability function is a mathematical function that describes the chance associated with a random variable having a particular outcome or falling within a given range of outcome values.

We can also distinguish two types of probability functions:

(1) **Probability Mass Functions (PMFs)** are associated with discrete random variables. These functions describe the probability that a random variable takes a particular discrete value.

To be a valid PMF, a function must satisfy the following

:   There are ùëòdistinct outcomes ùë•1,ùë•2,...,ùë•ùëò

:   Pr(X=xi) is greater than 0 and less than 1 for all xi

:   Sum of Pr(X = xi) for all x from x1 to xk = 1

### Flipping a Fair Coin

```{r}
outcomes <- c("heads", "tails")
prob <- c(1/2, 1/2)
barplot(prob, ylim = c(0, 0.6), names.arg = outcomes, space = 0.1, xlab =
          "outcome", ylab = "Pr(X = outcome)", main = "Probability Mass Function")
```

Cumulative Probability

```{r}
cumprob <- cumsum(prob)
barplot(cumprob, names.arg = outcomes, space = 0.1, xlab = "outcome", ylab = "Cumulative Pr(X)", main = "Cumulative Probability")
```

### Rolling a Fair Die

```{r}
outcomes <- c(1, 2, 3, 4, 5, 6)
prob <- c(1/6, 1/6, 1/6, 1/6, 1/6, 1/6)
barplot(prob, ylim = c(0, 0.5), names.arg = outcomes, space = 0.1, xlab = "outcome", ylab = "Pr(X = outcome)", main = "Probability Mass Function")
```

Cumulative Probability

```{r}
cumprob <- cumsum(prob)
barplot(cumprob, names.arg = outcomes, space = 0.1, xlab = "outcome", ylab = "Cumulative Pr(X)", main = "Cumulative Probability")
```

(2) **Probability Density Functions (PDFs)** are associated with continuous random variables. These functions describe the probability that a random variable falls within a given range of outcome values. The probability associated with that range equals the area under the density function for that range.

To be a valid PDF, a function must satisfy the following:
: The function is non-negative (greater than 0) for any given x
: The total area under the function = 1

### Example: Beta Distribution

The Beta Distribution refers to a family of continuous probability distributions defined over the interval [0, 1] and parametrized by two positive shape parameters, denoted by alpha (a) and beta (b), that appear as exponents of the random variable x and control the shape of the distribution.
 
f(x) = K * x^(a-1) *(1-x^(b - 1)) 

In this example, set K = 2, a = 2, and b = 1 and restrict domain of x to [0,1]

```{r}
library(ggplot2)
a <- 2
b <- 1
K <- 2
x <- seq(from = 0, to = 1, by = 0.025)
fx <- K * x^(a-1) * (1-x)^(b-1)
lower_x <- seq(from = -0.25, to = 0, by = 0.025)  # add some values of x less than zero
upper_x <- seq(from = 1, to = 1.25, by = 0.025)  # add some values of x greater than one
lower_fx <- rep(0, 11)  # add fx=0 values to x<0
upper_fx <- rep(0, 11)  # add fx=0 values to x>1
x <- c(lower_x, x, upper_x)  # paste xs together
fx <- c(lower_fx, fx, upper_fx)  # paste fxs together
d <- as.data.frame(cbind(x, fx))
p <- ggplot(data = d, aes(x = x, y = fx)) + xlab("x") + ylab("f(x)") + geom_line()
p
```

Show the above is a PDF

```{r}
library(manipulate)
manipulate(ggplot(data = d, aes(x = x, y = fx)) + xlab("x") + ylab("f(x)") +
    geom_line() + geom_polygon(data = data.frame(xvals = c(0, n, n, 0), fxvals = c(0,
    K * n^(a - 1) * (1 - n)^(b - 1), 0, 0)), aes(x = xvals, y = fxvals)) + ggtitle(paste("Area Under Function = ",
    0.5 * n * K * n^(a - 1) * (1 - n)^(b - 1), sep = " ")), n = slider(0, 1,
    initial = 0.5, step = 0.01))
```

The shaded area here represents the cumulative probability integrated across f(x) from ‚àíinf to x.

The **cumulative distribution function**, or CDF, of a random variable is defined as the probability of observing a random variable X taking the value of x or less, i.e. F(x) = Pr(X is less than or equal to x)
: This definition applies regardless of whether X is discrete or continuous. Note here we are using F(x) for the cumulative distribution function rather than f(x), which we use for the probability density function. For a continuous variable, the PDF is simply the first derivative of the CDF

```{r}
x <- seq(from = 0, to = 1, by = 0.005)
prob <- 0.5 * x * K * x^(a - 1) * (1 - x)^(b - 1)
barplot(prob, names.arg = x, space = 0, main = "Cumulative Probability", xlab = "x",ylab = "Pr(X ‚â§ x)")
```

The built in R function for the Beta Distribution, pbeta(), can give us the cumulative probability directly, if we specify the values of a = 2 and b = 1.
 
```{r}
pbeta(0.75, 2, 1)  # cumulative probability for x ‚â§ 0.75
pbeta(0.5, 2, 1)  # cumulative probability for x ‚â§ 0.50
```

In general, we find the cumulative probability for a continuous random variable by calculating the area under the probability density function of interest from -inf to x. This is what is is being returned from pbeta(). The other related Beta Distribution functions, e.g., rbeta(), dbeta(), and qbeta(), are also useful. rbeta() draws random observations from a specfied beta distribution. dbeta() gives the point estimate of the beta density function at the value of the argument x, and qbeta() is essentially the converse of pbeta(), i.e., it tells you the value of x that is associated with a particular cumulative probability, or quantile, of the cumulative distribution function. Other PMFs and PDFs have comparable r, d, p, and q functions.

```{r}
pbeta(0.7, 2, 1)  # yields .49
qbeta(0.49, 2, 1)  # yield 0.7
```

We can define the survival function for a random variable X as S(x) = P(X > x) = 1 - P (X <= X) = 1 - f(x)

Finally, we can define the ‚Äúqth‚Äù" quantile of a cumulative distibution function as the value of x at which the CDF has the value ‚Äúq‚Äù, i.e., F(x at q) = q

Expected Mean (u of x) and Variance (sigma^2 of x) of Random Variables

```{r}
m <- sum(seq(1:6) * 1/6)
m

var <- sum((seq(1:6) - mean(seq(1:6)))^2 * (1/6))
var
```

